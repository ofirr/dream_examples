{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dendropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/dcsoft/s/Ofir/DRAEM/pablo/sc2/'\n",
    "tns = dendropy.TaxonNamespace()\n",
    "ref_tree = dendropy.Tree.get_from_path(\n",
    "    os.path.join(project_dir,'SubC2_TEST_tree_IDs_root_rooted.nw'),'newick', taxon_namespace=tns, preserve_underscores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_taxa_labels = ['x_0828','x_0527','x_0248','x_0205','x_0811','x_0446','x_0551','x_0137','x_0861','x_0733',]\n",
    "relevant_taxa = tns.get_taxa(relevant_taxa_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ref = ref_tree.extract_tree_with_taxa(relevant_taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         /-------------- x_0828\n",
      "                                           /-------------+                     \n",
      "                            /--------------+             \\-------------- x_0527\n",
      "                            |              |                                   \n",
      "              /-------------+              \\---------------------------- x_0248\n",
      "              |             |                                                  \n",
      "              |             |                            /-------------- x_0205\n",
      "/-------------+             \\----------------------------+                     \n",
      "|             |                                          \\-------------- x_0811\n",
      "|             |                                                                \n",
      "+             \\--------------------------------------------------------- x_0446\n",
      "|                                                                              \n",
      "|                           /------------------------------------------- x_0551\n",
      "|                           |                                                  \n",
      "\\---------------------------+                            /-------------- x_0137\n",
      "                            |              /-------------+                     \n",
      "                            \\--------------+             \\-------------- x_0861\n",
      "                                           |                                   \n",
      "                                           \\---------------------------- x_0733\n",
      "                                                                               \n",
      "                                                                               \n"
     ]
    }
   ],
   "source": [
    "print(sub_ref.as_ascii_plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_trivial_partitions(tree):\n",
    "    leaves = set(tree.leaf_nodes())\n",
    "    total = len(leaves)\n",
    "    for n in tree.nodes():\n",
    "        if len(n.leaf_nodes()) == 1:\n",
    "            continue\n",
    "        if len(n.leaf_nodes()) == total:\n",
    "            continue\n",
    "        p = frozenset({l.taxon.label for l in n.leaf_nodes()})\n",
    "        yield n, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_trees = dict()\n",
    "for rec_name in [\n",
    "    'Kwak_Gong_rooted.nw',\n",
    "    'SanGuo1_rooted.nw',\n",
    "    'YFG_Hanrui_rooted.nw',\n",
    "    'Yosef_Lab_rooted.nw',\n",
    "    'Jasper06_rooted.nw',\n",
    "    'submissions_merged.nw',\n",
    "]:\n",
    "    rec_tree = dendropy.Tree.get_from_path(\n",
    "        os.path.join(project_dir,rec_name),'newick', taxon_namespace=tns, preserve_underscores=True)\n",
    "    sub_rec = rec_tree.extract_tree_with_taxa(relevant_taxa)\n",
    "    rec_trees[rec_name] = rec_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fresh_node_copy(tree, node):\n",
    "    for fresh_node in tree.postorder_node_iter():\n",
    "        if fresh_node.taxon != node.taxon:\n",
    "            continue        \n",
    "        return fresh_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248', 'x_0446'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248', 'x_0446'})\" SanGuo1 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248', 'x_0446'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248', 'x_0446'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248', 'x_0446'})\" Jasper06 0\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248', 'x_0446'})\" submissions 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248'})\" SanGuo1 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248'})\" Jasper06 0\n",
      "\"frozenset({'x_0811', 'x_0527', 'x_0828', 'x_0205', 'x_0248'})\" submissions 1\n",
      "\"frozenset({'x_0527', 'x_0828', 'x_0248'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0527', 'x_0828', 'x_0248'})\" SanGuo1 1\n",
      "\"frozenset({'x_0527', 'x_0828', 'x_0248'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0527', 'x_0828', 'x_0248'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0527', 'x_0828', 'x_0248'})\" Jasper06 0\n",
      "\"frozenset({'x_0527', 'x_0828', 'x_0248'})\" submissions 1\n",
      "\"frozenset({'x_0527', 'x_0828'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0527', 'x_0828'})\" SanGuo1 1\n",
      "\"frozenset({'x_0527', 'x_0828'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0527', 'x_0828'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0527', 'x_0828'})\" Jasper06 0\n",
      "\"frozenset({'x_0527', 'x_0828'})\" submissions 1\n",
      "\"frozenset({'x_0205', 'x_0811'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0205', 'x_0811'})\" SanGuo1 1\n",
      "\"frozenset({'x_0205', 'x_0811'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0205', 'x_0811'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0205', 'x_0811'})\" Jasper06 0\n",
      "\"frozenset({'x_0205', 'x_0811'})\" submissions 1\n",
      "\"frozenset({'x_0861', 'x_0551', 'x_0137', 'x_0733'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0861', 'x_0551', 'x_0137', 'x_0733'})\" SanGuo1 1\n",
      "\"frozenset({'x_0861', 'x_0551', 'x_0137', 'x_0733'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0861', 'x_0551', 'x_0137', 'x_0733'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0861', 'x_0551', 'x_0137', 'x_0733'})\" Jasper06 0\n",
      "\"frozenset({'x_0861', 'x_0551', 'x_0137', 'x_0733'})\" submissions 1\n",
      "\"frozenset({'x_0861', 'x_0137', 'x_0733'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0861', 'x_0137', 'x_0733'})\" SanGuo1 1\n",
      "\"frozenset({'x_0861', 'x_0137', 'x_0733'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0861', 'x_0137', 'x_0733'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0861', 'x_0137', 'x_0733'})\" Jasper06 0\n",
      "\"frozenset({'x_0861', 'x_0137', 'x_0733'})\" submissions 1\n",
      "\"frozenset({'x_0861', 'x_0137'})\" Kwak_Gong 1\n",
      "\"frozenset({'x_0861', 'x_0137'})\" SanGuo1 1\n",
      "\"frozenset({'x_0861', 'x_0137'})\" YFG_Hanrui 1\n",
      "\"frozenset({'x_0861', 'x_0137'})\" Yosef_Lab 1\n",
      "\"frozenset({'x_0861', 'x_0137'})\" Jasper06 0\n",
      "\"frozenset({'x_0861', 'x_0137'})\" submissions 1\n"
     ]
    }
   ],
   "source": [
    "for n, p in get_non_trivial_partitions(sub_ref):\n",
    "    for rec_name, rec_tree in rec_trees.items():\n",
    "#         print('\"{}\"'.format(p), rec_name[:-10], p in set(get_non_trivial_partitions(sub_rec)))\n",
    "        compute_transfer_inds(ref_tree,rec_tree)\n",
    "        print('\"{}\"'.format(p), rec_name[:-10], get_fresh_node_copy(ref_tree, n).dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pure python implementations by the Booster people (updated to Python3)\n",
    "https://bitbucket.org/thekswenson/rapid_transferindex/src/default/transfer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dendropy\n",
    "import sys\n",
    "from collections import deque\n",
    "import copy\n",
    "from math import ceil,log,exp\n",
    "import re\n",
    "\n",
    "from dendropy.simulate import treesim #for tests only\n",
    "\n",
    "#a string for fake taxon names - needed for pruning identical subtrees\n",
    "shrink_subtrees=True\n",
    "arttaxstr='ArtTaxon'\n",
    "\n",
    "pardict={}\n",
    "leftdict={}\n",
    "rightdict={}\n",
    "minvaldict={}\n",
    "maxvaldict={}\n",
    "ddict={}\n",
    "counter=0\n",
    "parent_node={}\n",
    "taxon_id={}\n",
    "\n",
    "path_num={}\n",
    "\n",
    "min_glob=1000000000\n",
    "max_glob=-1000000000\n",
    "comp_list=[]\n",
    "comp_list_zero=[]\n",
    "\n",
    "\n",
    "def reset_extrema():\n",
    "    global min_glob,max_glob,comp_list_zero,comp_list\n",
    "    min_glob=1000000000\n",
    "    max_glob=-1000000000\n",
    "    comp_list=comp_list_zero # reset the data structure without building from scratch\n",
    "\n",
    "\n",
    "def count_desc_leaves(T):\n",
    "    for node in T.postorder_node_iter():\n",
    "        if node.is_leaf():\n",
    "            node.nleaves=1\n",
    "        else:\n",
    "            node.nleaves=sum([nd.nleaves for nd in node.child_nodes()])\n",
    "    return T.seed_node.nleaves\n",
    "\n",
    "\n",
    "def find_max_child(node):\n",
    "    maxnl=0\n",
    "    mchild=None\n",
    "    others=[]\n",
    "    for child in node.child_nodes():\n",
    "        if child.nleaves>maxnl:\n",
    "            maxnl=child.nleaves\n",
    "            if mchild is not None:\n",
    "                others.append(mchild)\n",
    "            mchild=child\n",
    "        else:\n",
    "            others.append(child)\n",
    "    assert mchild!=None\n",
    "    return mchild,others\n",
    "\n",
    "\n",
    "\n",
    "# returns a list of heavy paths\n",
    "def get_heavy_paths(T):\n",
    "    paths=[]\n",
    "    q=deque()\n",
    "    q.append(T.seed_node)\n",
    "    \n",
    "    while q:\n",
    "        curnode=q.popleft()\n",
    "        path=[curnode]\n",
    "        assert curnode is not None\n",
    "        while not curnode.is_leaf():\n",
    "            mchild,others=find_max_child(curnode)\n",
    "            assert mchild is not None\n",
    "            q.extend(others)\n",
    "            curnode=mchild\n",
    "            path.append(curnode)\n",
    "        paths.append(path)\n",
    "\n",
    "    return paths\n",
    "\n",
    "def assign_ids_to_nodes(T):\n",
    "    cnt=0\n",
    "    for node in T.preorder_node_iter():\n",
    "        node.id=cnt\n",
    "        cnt=cnt+1\n",
    "\n",
    "def pick_midpoint(path,aind,bind):\n",
    "    assert aind<bind\n",
    "    return aind+(bind-aind)//2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_up_path_search_tree_simple(path):\n",
    "    global pardict,leftdict,rightdict,minvaldict,maxvaldict,ddict\n",
    "\n",
    "    pathids=[x.id for x in path]\n",
    "    pathleafnums=[x.nleaves for x in path]\n",
    "    q=deque()\n",
    "    root_int_index=(0,len(path)-1)\n",
    "    pardict[(pathids[0],pathids[-1])]=None\n",
    "    q.append(root_int_index)\n",
    "    while q:\n",
    "        (aind,bind)=q.popleft()\n",
    "        a=pathids[aind]; b=pathids[bind]\n",
    "        curint=(a,b)\n",
    "        minvaldict[curint]=pathleafnums[bind]\n",
    "        maxvaldict[curint]=pathleafnums[aind]\n",
    "\n",
    "        if a==b:\n",
    "            ddict[curint]=pathleafnums[bind]\n",
    "        else:\n",
    "            ddict[curint]=0\n",
    "\n",
    "            mid=pick_midpoint(path,aind,bind)\n",
    "            leftint=(a,pathids[mid])\n",
    "            q.append((aind,mid))\n",
    "            rightint=(pathids[mid+1],b)\n",
    "            q.append((mid+1,bind))\n",
    "            pardict[leftint]=curint\n",
    "            pardict[rightint]=curint\n",
    "            leftdict[curint]=leftint\n",
    "            rightdict[curint]=rightint\n",
    "\n",
    "#### end of set_up_path_search_tree_simple\n",
    "\n",
    "def set_up_parents(T):\n",
    "    global parent_node\n",
    "    for node in T.postorder_node_iter():\n",
    "        if node.parent_node is not None:\n",
    "            parent_node[node.id]=node.parent_node.id\n",
    "        else:\n",
    "            parent_node[node.id]=None\n",
    "\n",
    "def set_up_taxon_ids(T):\n",
    "    global taxon_id\n",
    "    for leaf in T.leaf_nodes():\n",
    "        taxon_id[leaf.taxon.label]=leaf.id\n",
    "\n",
    "def copy_taxon_ids(T):\n",
    "    global taxon_id\n",
    "    for leaf in T.leaf_nodes():\n",
    "        leaf.id=taxon_id[leaf.taxon.label]\n",
    "\n",
    "def set_up_visit_marks(T):\n",
    "    for node in T.postorder_node_iter():\n",
    "        node.visited=False\n",
    "\n",
    "def set_up_everything(T):\n",
    "    global parent_node,counter,path_num,maxvaldict,comp_list,comp_list_zero\n",
    "    #count_desc_leaves(T) #well, this has to be done separately...\n",
    "    assign_ids_to_nodes(T)\n",
    "    set_up_parents(T)\n",
    "\n",
    "    set_up_taxon_ids(T)\n",
    "    \n",
    "\n",
    "    paths=get_heavy_paths(T)\n",
    "    maxima=[0 for i in range(len(paths))]\n",
    "    for i in range(len(paths)):\n",
    "        set_up_path_search_tree_simple(paths[i])\n",
    "        #now set up the data structure for maxima\n",
    "        root_int=(paths[i][0].id,paths[i][-1].id)\n",
    "        path_num[root_int]=i\n",
    "        maxima[i]=maxvaldict[root_int]\n",
    "\n",
    "    #now create the data structure\n",
    "    comp_list=make_comp_list(maxima)\n",
    "    comp_list_zero=comp_list\n",
    "\n",
    "\n",
    "def update_path(nodeid,d):\n",
    "    global ddict,minvaldict,maxvaldict,pardict,leftdict\n",
    "    global min_glob,comp_list,path_num\n",
    "\n",
    "    cur_int=(nodeid,nodeid)\n",
    "    ddict[cur_int]+=d\n",
    "    minvaldict[cur_int]+=d\n",
    "    maxvaldict[cur_int]+=d\n",
    "\n",
    "    while pardict[cur_int] is not None:\n",
    "        par_int=pardict[cur_int]\n",
    "        left_int=leftdict[par_int]\n",
    "        right_int=rightdict[par_int]\n",
    "        if par_int[1]==cur_int[1]:\n",
    "            ddict[left_int]+=d\n",
    "            minvaldict[left_int]+=d\n",
    "            maxvaldict[left_int]+=d\n",
    "        minvaldict[par_int]=min(minvaldict[left_int],minvaldict[right_int])+ddict[par_int]\n",
    "        maxvaldict[par_int]=max(maxvaldict[left_int],maxvaldict[right_int])+ddict[par_int]\n",
    "        cur_int=par_int\n",
    "    if minvaldict[cur_int]<min_glob:\n",
    "        min_glob=minvaldict[cur_int]\n",
    "    #if maxvaldict[cur_int]>max_glob:\n",
    "    #    max_glob=maxvaldict[cur_int]\n",
    "    update_comp_list(comp_list,path_num[cur_int],maxvaldict[cur_int])\n",
    "\n",
    "    return cur_int\n",
    "\n",
    "#adds (direction=+1) or deletes (direction=-1) the leaf from the working set\n",
    "def change_leaf_status(nodeid,direction):\n",
    "    global counter,parent_node\n",
    "    counter+=direction\n",
    "    (first,last)=update_path(nodeid,-2*direction)\n",
    "    while first!=0:\n",
    "        x=parent_node[first]\n",
    "        (first,last)=update_path(x,-2*direction)\n",
    "\n",
    "def get_leaf_id(leaf):\n",
    "    tlabel=leaf.taxon.label\n",
    "    tid=taxon_id[tlabel]\n",
    "    return tid\n",
    "\n",
    "def get_sibling(node):\n",
    "    parent=node.parent_node\n",
    "    for nd in parent.child_nodes():\n",
    "        if nd!=node:\n",
    "            return nd\n",
    "\n",
    "\n",
    "def compute_transfer_inds(T,Tother):\n",
    "    global counter\n",
    "    global shrink_subtrees\n",
    "    T.resolve_polytomies()\n",
    "    Tother.resolve_polytomies()\n",
    "    nleaves=count_desc_leaves(T)\n",
    "    count_desc_leaves(Tother)\n",
    "    if shrink_subtrees:\n",
    "        nodesT,nodesT2=find_max_ident_subtrees(T,Tother)\n",
    "        if len(nodesT)<=1:\n",
    "            #assert len(nodesT2)\n",
    "            for node in T.postorder_node_iter():\n",
    "                node.dist=0\n",
    "                return\n",
    "        removedT=detach_subtrees(T,nodesT)\n",
    "        removedT2=detach_subtrees(Tother,nodesT2)\n",
    "    else:\n",
    "        for leaf in T.leaf_nodes():\n",
    "            leaf.weight=1\n",
    "    set_up_everything(Tother)\n",
    "    copy_taxon_ids(T)\n",
    "    set_up_visit_marks(T)\n",
    "    #display_param(Tother,invariant)\n",
    "    for leaf in T.leaf_nodes():\n",
    "        leaf.dist=0 # there's always a leaf like that in the other tree\n",
    "        node=leaf\n",
    "        #print \"adding as first:\"+str(node.taxon.label)\n",
    "        change_leaf_status(node.id,node.weight)\n",
    "        #display_param(Tother,invariant)\n",
    "        while node.parent_node is not None:\n",
    "            #for now, let's just do binary trees\n",
    "            parent=node.parent_node\n",
    "            if node.nleaves*2>=parent.nleaves and not parent.visited:\n",
    "                sibling=get_sibling(node)\n",
    "                for sideleaf in sibling.leaf_nodes():\n",
    "                    #print \"adding:\"+str(sideleaf.taxon.label)\n",
    "                    change_leaf_status(sideleaf.id,sideleaf.weight)\n",
    "\n",
    "                max_glob=comp_list[1]\n",
    "\n",
    "                mindist=min(min_glob+counter,nleaves-max_glob-counter)\n",
    "                parent.dist=mindist\n",
    "                parent.visited=True\n",
    "                node=parent\n",
    "            else:\n",
    "                #print \"REMOVING LEAVES:\"\n",
    "                for descleaf in node.leaf_nodes():\n",
    "                    change_leaf_status(descleaf.id,-descleaf.weight)\n",
    "                    #print \"removing:\"+str(descleaf.taxon.label)\n",
    "                    #display_param(Tother,invariant)\n",
    "                reset_extrema()\n",
    "                break\n",
    "            #display_param(Tother,invariant)\n",
    "\n",
    "        if node.parent_node is None: # reached the root, must clean up everything\n",
    "            for descleaf in node.leaf_nodes():\n",
    "                change_leaf_status(descleaf.id,-descleaf.weight)\n",
    "                #print \"removing:\"+str(descleaf.taxon.label)\n",
    "                #display_param(Tother,invariant)\n",
    "            reset_extrema()\n",
    "    #end of main loop\n",
    "    if shrink_subtrees:\n",
    "        reattach_subtrees(T,nodesT,removedT)\n",
    "        reattach_subtrees(Tother,nodesT2,removedT2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_transfer_inds_naive(T,Tother):\n",
    "    count_desc_leaves(Tother)\n",
    "    set_up_everything(Tother)\n",
    "    nleaves=count_desc_leaves(T)\n",
    "    copy_taxon_ids(T)\n",
    "    wholeset=set([x.id for x in T.leaf_nodes()])\n",
    "    for node in T.postorder_node_iter():\n",
    "        curset=set([x.id for x in node.leaf_nodes()])\n",
    "        mindist=10000000\n",
    "\n",
    "        for node2 in Tother.postorder_node_iter():\n",
    "            curset2=set([x.id for x in node2.leaf_nodes()])\n",
    "            dist1=len(curset^curset2)\n",
    "            dist2=len((wholeset-curset)^curset2)\n",
    "            dist=min(dist1,dist2)\n",
    "            if dist<mindist:\n",
    "                mindist=dist\n",
    "\n",
    "        node.naivedist=mindist\n",
    "\n",
    "\n",
    "# collapsing identical subtrees to speed up execution\n",
    "\n",
    "def get_pseudoleaves(nd):\n",
    "    return [node for node in nd.postorder_iter(lambda x: x.pseudoleaf)]\n",
    "\n",
    "def find_maximal_identical_subtrees(T,Tother):\n",
    "    t1nodedict={}\n",
    "    nodesfirst=[]\n",
    "    nodessecond=[]\n",
    "    for node in T.postorder_node_iter():\n",
    "        node.pseudoleaf=False\n",
    "        if node.is_leaf():\n",
    "            taxstr=str(node.taxon.label)\n",
    "            node.tup=(taxstr,taxstr)\n",
    "            t1nodedict[node.tup]=node\n",
    "            node.dist=0\n",
    "        else:\n",
    "            tup=tuple(min(child.tup) for child in node.child_nodes())\n",
    "            node.tup=tup\n",
    "            t1nodedict[tup]=node\n",
    "            node.dist=0 # will be overwritten later anyway\n",
    "\n",
    "    for node in Tother.postorder_node_iter():\n",
    "        node.pseudoleaf=False\n",
    "        if node.is_leaf():\n",
    "            taxstr=str(node.taxon.label)\n",
    "            node.tup=(taxstr,taxstr)\n",
    "            node.has_exact_match=True\n",
    "            node.dist=0\n",
    "        else:\n",
    "            tup=tuple(min(child.tup) for child in node.child_nodes())\n",
    "            node.tup=tup\n",
    "            if tup in t1nodedict and all([child.has_exact_match for child in node.child_nodes()]):\n",
    "                node.has_exact_match=True\n",
    "                node.dist=0\n",
    "            else:\n",
    "                node.has_exact_match=False\n",
    "                for child in node.child_nodes():\n",
    "                    if child.has_exact_match:\n",
    "                        nodessecond.append(child)\n",
    "                        child.pseudoleaf=True\n",
    "                        nodesfirst.append(t1nodedict[child.tup])\n",
    "                        t1nodedict[child.tup].pseudoleaf=True\n",
    "\n",
    "    T.pseudoleaves=nodesfirst\n",
    "    Tother.pseudoleaves=nodessecond\n",
    "    return nodesfirst,nodessecond                    \n",
    "\n",
    "def find_max_ident_subtrees(T,Tother):\n",
    "    leaves_by_taxon={}\n",
    "    nodesfirst=[]\n",
    "    nodessecond=[]\n",
    "    for leaf in T.leaf_nodes():\n",
    "        leaves_by_taxon[leaf.taxon.label]=leaf\n",
    "\n",
    "    for node in T.postorder_node_iter():\n",
    "        node.pseudoleaf=False\n",
    "        node.dist=0\n",
    "\n",
    "    for node in Tother.postorder_node_iter():\n",
    "        node.pseudoleaf=False\n",
    "        node.dist=0\n",
    "\n",
    "    for leaf in Tother.leaf_nodes():\n",
    "        leaf.other=leaves_by_taxon[leaf.taxon.label]\n",
    "        leaf.has_exact_match=True\n",
    "        leaf.dist=0\n",
    "\n",
    "    for node in Tother.postorder_node_iter():\n",
    "        if node.is_leaf():\n",
    "            continue\n",
    "        if all([child.has_exact_match for child in node.child_nodes()]):\n",
    "            otherparents=[child.other.parent_node for child in node.child_nodes()]\n",
    "            if all([par==otherparents[0] for par in otherparents]):\n",
    "                node.has_exact_match=True\n",
    "                node.dist=0\n",
    "                node.other=otherparents[0]\n",
    "            else:\n",
    "                #node is not a repeated subtree but all of its children are\n",
    "                node.has_exact_match=False\n",
    "                for child in node.child_nodes():\n",
    "                    nodesfirst.append(child)\n",
    "                    nodessecond.append(child.other)\n",
    "                    child.pseudoleaf=True\n",
    "                    child.other.pseudoleaf=True\n",
    "\n",
    "        else:\n",
    "            #one of the children doesn't have a matching subtree so just mark False\n",
    "            node.has_exact_match=False\n",
    "            for child in node.child_nodes():\n",
    "                    if not child.has_exact_match:\n",
    "                        continue\n",
    "                    nodesfirst.append(child)\n",
    "                    nodessecond.append(child.other)\n",
    "                    child.pseudoleaf=True\n",
    "                    child.other.pseudoleaf=True\n",
    "\n",
    "    T.pseudoleaves=nodesfirst\n",
    "    Tother.pseudoleaves=nodessecond\n",
    "    return nodesfirst,nodessecond\n",
    "        \n",
    "\n",
    "def detach_subtrees(T,subroots):\n",
    "    removed=[]\n",
    "    for i in range(len(subroots)):\n",
    "        node=subroots[i]\n",
    "        node.weight=len(node.leaf_nodes())\n",
    "        children=[]\n",
    "        for child in node.child_nodes():\n",
    "            children.append(child)\n",
    "            node.remove_child(child)\n",
    "        removed.append(children)\n",
    "        if len(children)>0:\n",
    "            node.taxon=dendropy.Taxon(label=arttaxstr+str(i))\n",
    "\n",
    "    return removed\n",
    "\n",
    "def reattach_subtrees(T,subroots,removed):\n",
    "    assert len(subroots)==len(removed)\n",
    "    for i in range(len(subroots)):\n",
    "        for child in removed[i]:\n",
    "            subroots[i].add_child(child)\n",
    "        if not subroots[i].is_leaf():\n",
    "            subroots[i].taxon=None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dists_as_blengths(T):\n",
    "    for node in T.postorder_node_iter():\n",
    "        node.edge_length=node.naivedist\n",
    "\n",
    "def dists_as_blengths2(T):\n",
    "    for node in T.postorder_node_iter():\n",
    "        node.edge_length=node.dist\n",
    "\n",
    "def invariant(node):\n",
    "    global pardict\n",
    "    global ddict\n",
    "    x=node.id\n",
    "    cur_int=(x,x)\n",
    "    acc=ddict[cur_int]\n",
    "    while pardict[cur_int] is not None:\n",
    "        cur_int=pardict[cur_int]\n",
    "        acc+=ddict[cur_int]\n",
    "    return acc+counter\n",
    "\n",
    "\n",
    "def display_param(T,func):\n",
    "    Tdisplay=copy.deepcopy(T)\n",
    "    for node in Tdisplay.postorder_node_iter():\n",
    "        node.edge_length=func(node)\n",
    "    print(Tdisplay)\n",
    "\n",
    "\n",
    "#-----------Data structure for maintaining max in a fixed-size but mutable set\n",
    "\n",
    "\n",
    "def make_comp_list(lst):\n",
    "\n",
    "    total_size=int(2**(ceil(log(len(lst),2)))*2)\n",
    "    aux_elem_size=total_size//2\n",
    "    comp_list=[0 for i in range(aux_elem_size)]\n",
    "    comp_list.extend(lst)\n",
    "    null_val=-1000000000\n",
    "    comp_list.extend([null_val for i in range(len(comp_list),total_size)])\n",
    "\n",
    "    for i in range(aux_elem_size-1,0,-1):#1 is the index of the global max\n",
    "        leftchild=2*i\n",
    "        rightchild=leftchild+1\n",
    "        comp_list[i]=max(comp_list[leftchild],comp_list[rightchild])\n",
    "    return comp_list\n",
    "\n",
    "def update_comp_list(comp_list,lst_index,val):\n",
    "    \n",
    "    internal_ind=len(comp_list)//2+lst_index\n",
    "    comp_list[internal_ind]=val\n",
    "    while internal_ind>1:\n",
    "        internal_ind//=2\n",
    "        leftchild=internal_ind*2\n",
    "        rightchild=leftchild+1\n",
    "        newval=max(comp_list[leftchild],comp_list[rightchild])\n",
    "        if newval==comp_list[internal_ind]:\n",
    "            break\n",
    "        comp_list[internal_ind]=newval\n",
    "    return comp_list[1]\n",
    "\n",
    "#------End of data structure\n",
    "\n",
    "#------Transfer bootstrap expectation (TBE)------\n",
    "\n",
    "def add_TS(reftree,btree):\n",
    "    compute_transfer_inds(reftree,btree)\n",
    "\n",
    "    for node in reftree.postorder_node_iter():\n",
    "        node.indsum+=node.dist\n",
    "\n",
    "def compute_TBE(reftree,bstrings):\n",
    "    reftree.resolve_polytomies()\n",
    "    for node in reftree.postorder_node_iter():\n",
    "        node.indsum=0.0\n",
    "\n",
    "    tnum=0\n",
    "    for bstring in bstrings:\n",
    "        print(\"Processing tree #:\"+str(tnum), file=sys.stderr)\n",
    "        btree=dendropy.Tree.get_from_string(bstring,schema='newick',case_sensitive_taxon_labels=True,taxon_namespace=reftree.taxon_namespace)\n",
    "        add_TS(reftree,btree)\n",
    "        tnum+=1\n",
    "\n",
    "    nboot=len(bstrings)\n",
    "    totalleaves=count_desc_leaves(reftree)\n",
    "    for node in reftree.postorder_node_iter():\n",
    "        node.indsum=node.indsum/nboot # get the average transfer index\n",
    "        if node.nleaves==1 or node.nleaves==totalleaves-1 or node.parent_node is None:\n",
    "            node.support=1.0\n",
    "        else:\n",
    "            node.support=1.0-node.indsum/(min(node.nleaves,totalleaves-node.nleaves)-1)\n",
    "\n",
    "def display_support_values(reftree):\n",
    "    for node in reftree.postorder_node_iter():\n",
    "        if not node.is_leaf() and not node.parent_node is None:\n",
    "            node.label=str(node.support)\n",
    "\n",
    "\n",
    "def read_bootstrap_trees(bpath):\n",
    "    btreelist=dendropy.TreeList.get(path=bpath,schema='newick')\n",
    "    return btreelist\n",
    "\n",
    "#returns list of newick strings to be parsed one by one \n",
    "def read_boostrap_trees_long(bpath):\n",
    "    F=file(bpath,\"r\")\n",
    "    wholestr=F.read()\n",
    "    treestraw=wholestr.split(';')\n",
    "    treesttrimmed=[x for x in [x.strip()+';' for x in treestraw] if x[0]=='(']\n",
    "    return treesttrimmed\n",
    "\n",
    "#inserts special chars to disambiguate lower- and uppercase after they're conflated\n",
    "\n",
    "def fix_uppercase(treestr):\n",
    "    upcase_mark='wxyzab'\n",
    "    modst=re.sub('[A-Z]',lambda x:x.group()+upcase_mark,treestr)\n",
    "    return modst\n",
    "\n",
    "def undo_fix_uppercase(modst):\n",
    "    upcase_mark='wxyzab'\n",
    "    treest=re.sub(upcase_mark,'',modst)\n",
    "    return treest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------End of TBE\n",
    "\n",
    "#----TESTS----\n",
    "\n",
    "def verify_dist(T):\n",
    "\n",
    "    for node in T.postorder_node_iter():\n",
    "        assert node.dist==node.naivedist\n",
    "\n",
    "def test_rand_trees(treesize):\n",
    "    T=treesim.birth_death_tree(1.0,0.0,ntax=treesize)\n",
    "    T2=treesim.birth_death_tree(1.0,0.0,num_extant_tips=treesize,taxon_namespace=T.taxon_namespace)\n",
    "    \n",
    "    compute_transfer_inds(T,T2)\n",
    "    compute_transfer_inds_naive(T,T2)\n",
    "\n",
    "    verify_dist(T)\n",
    "\n",
    "def test_same_trees(treesize):\n",
    "    T=treesim.birth_death_tree(1.0,0.0,ntax=treesize)\n",
    "    T2=copy.deepcopy(T)\n",
    "    compute_transfer_inds(T,T2)\n",
    "    compute_transfer_inds_naive(T,T2)\n",
    "\n",
    "    verify_dist(T)\n",
    "\n",
    "def random_tree_test(treesize,ntests):\n",
    "    for i in range(ntests):\n",
    "        print(\"two random trees, test:\"+str(i))\n",
    "        test_rand_trees(treesize)\n",
    "\n",
    "def random_tree_speed_test(treesize,ntests):\n",
    "    for i in range(ntests):\n",
    "        if i%10==0:\n",
    "            print(\"two random trees, testing speed:\"+str(i))\n",
    "        T=treesim.birth_death_tree(1.0,0.0,ntax=treesize)\n",
    "        T2=treesim.birth_death_tree(1.0,0.0,num_extant_tips=treesize,taxon_namespace=T.taxon_namespace)\n",
    "        compute_transfer_inds(T,T2)\n",
    "\n",
    "def same_tree_test(treesize,ntests):\n",
    "    for i in range(ntests):\n",
    "        print(\"two equal trees, test:\"+str(i))\n",
    "        test_same_trees(treesize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
